#!/usr/bin/env python
# Copyright 2012 Jan Pokorny <xpokor04@stud.fit.vutbr.cz,
#                             pokorny_jan@seznam.cz>
#
# This file is part of clsp/predator.
#
# predator is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# any later version.
#
# predator is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with predator.  If not, see <http://www.gnu.org/licenses/>.
"""/
Program that for two input files (presumably representing a linearized code)
tries to "adjust" (memory) addresses and optionally register numbers
in the first file to fit those in the other.

It's intended to be used prior to comparing such two files (in case we expect
these files are isomorphic except for addresses and/or register numbers).

Currently, the algorithm tolerates a line displacement of OFFSET_LIMIT
(line X in the first file expected to correspond to line Y..Y+OFFSET_LIMIT
in the other, where initially X=Y), but probably not robust enough, though.

Note: currently with sparse, random numbers with "bad pseudo types" are quite
      annoying, but there is an option in my favorite meld to ignore lines
      with certain patterns (but could be handled also from here)
"""

# for `file=stderr' argument with older Python versions (2.6 probably minimum)
from __future__ import print_function

__author__ = "Jan Pokorny <xpokor04@stud.fit.vutbr.cz,pokorny_jan@seznam.cz>"

from sys import argv, stdout, stderr, exit as sysexit
from os.path import exists, split
from os import stat, makedirs
import re


VERBOSITY_FILE_TO_PROCESS    = False
VERBOSITY_NOTES              = False
VERBOSITY_MATCHES_DIFFER_MAX = 10

# tolerated corresponding lines displacement between the two files
OFFSET_LIMIT                 = 0
# whether to redefine already planned substitution
DO_SUBST_REDEF               = True


# RE definitions
# Note: group names required to distinguish them in proceeding,
#       anonymous groups at the beginning do not matter.

# address: hexadecimal number (of arbitrary length) prefixed with "0x"
#          but not with "$0x" (which denotes immediate value)
#RE_ADDR_STR   = r"(?:^|[^$]|\B)(?P<addr>0x[0-9a-fA-F]+\b)"
# version matching only against BB "labels"
RE_ADDR_STR   = r"(?:.L)(?P<addr>0x[0-9a-fA-F]+\b)"
# register number: decimal number (of arbitrary length) prefixed with "%r"
RE_REGNUM_STR = r"(?P<regnum>%r[1-9][0-9]*\b)"


def open_smarter(name, mode):
    # http://stackoverflow.com/questions/273192/
    d, base = split(name)
    if d is not "":
        try:
            stat(d)
        except:
            makedirs(d)
    return open(name, mode), base

def mobj_to_strgrp(matchobj):
    return (matchobj.lastgroup, matchobj.group(matchobj.lastindex))

# Note: using inputs as lists of items generated with function above.
def same_strgrp_lists(strgrp_list1, strgrp_list2):
    if len(strgrp_list1) != len(strgrp_list2):
        return False
    for g1, g2 in zip(strgrp_list1, strgrp_list2):
        if g1[0] != g2[0]:
            return False
    return True

def batch_substitution_apply_faster(matches_dict, adj_text):
    """Apply batch substitution on `adj_text' according to `matches_dict'.

    Contrary to `batch_substitution_apply_better', this can make undesired
    substitutions of yet substituted patterns.  OTOH, it's noticeably faster.
    """
    for adj_ptrn, src_dict in matches_dict.iteritems():
        # take most frequented "src_pattern"
        if (len(src_dict) == 1):
            # common shortcut when there is the only candidate
            src_ptrn = src_dict.keys()[0]
        else:
            src_ptrn = dict(
                           zip(src_dict.values(), src_dict.keys())
                       )[max(src_dict.values())]
        #print("%s -> %s" % (adj_ptrn, src_dict.items()))
        #print("%s -> %s" % (adj_ptrn, src_ptrn))
        adj_ptrn_re = re.compile(adj_ptrn + r"\b")
        adj_text = adj_ptrn_re.sub(src_ptrn, adj_text)
    return adj_text

def batch_substitution_apply_better(matches_dict, adj_text):
    """Apply batch substitution on `adj_text' according to `matches_dict'."""
    TEMPORARY_MARK = "@@"
    for adj_ptrn, src_dict in matches_dict.iteritems():
        # take most frequented "src_pattern"
        if (len(src_dict) == 1):
            # common shortcut when there is the only candidate
            src_ptrn = src_dict.keys()[0]
        else:
            src_ptrn = dict(
                           zip(src_dict.values(), src_dict.keys())
                       )[max(src_dict.values())]
        #print("%s -> %s" % (adj_ptrn, src_dict.items()))
        #print("%s -> %s" % (adj_ptrn, src_ptrn))
        adj_ptrn_re = re.compile("(?<!"+TEMPORARY_MARK+")" + adj_ptrn + r"\b")
        adj_text = adj_ptrn_re.sub(TEMPORARY_MARK + src_ptrn, adj_text)
    return adj_text.replace(TEMPORARY_MARK, "")

def batch_substitution_add(matches_dict, adj_matches, src_matches):
    """\
    Remember possible substitutions in `matches_dict', which has a form
    "{adj_pattern1: {src_pattern1: occurencies_num, ...}, ...}"
    """
    for adj_match, src_match in zip(adj_matches, src_matches):
        #print(adj_match[1])
        if adj_match[1] == src_match[1]:
            src_dict = matches_dict.setdefault(adj_match[1], {})
            src_dict[src_match[1]] = 99  # make it hard to be overriden
            continue
        src_dict = matches_dict.setdefault(adj_match[1], {})
        if src_dict is {} or DO_SUBST_REDEF:
            cnt = src_dict.setdefault(src_match[1], 0)
            src_dict[src_match[1]] = cnt+1 #+ (src_lnum-len(src_dict))/2

def addr_reg_adj(adj_text, src_text, pattern, subst_apply_f, dest_file="-"):
    re_ptrn = re.compile(pattern)

    if dest_file == "-":
        fdst, base = stdout, dest_file
    else:
        fdst, base = open_smarter(dest_file, "w")
        if VERBOSITY_FILE_TO_PROCESS:
            print(dest_file)

    adj_lines = adj_text.split("\n"); adj_lnum = len(adj_lines)
    src_lines = src_text.split("\n"); src_lnum = len(src_lines)
    if adj_lnum != src_lnum:
        print("warning: number of lines differ between files (%d, %d)"
              % (adj_lnum, src_lnum), file=stderr)

    matches_dict = {}
    matches_differ_cnt =  0
    offset_max = OFFSET_LIMIT/2
    adj_cnt = src_cnt = 0

    while adj_cnt < adj_lnum and src_cnt < src_lnum:
        offset_pos = 0
        adj_matches = map(mobj_to_strgrp, re_ptrn.finditer(adj_lines[adj_cnt]))
        src_matches = map(mobj_to_strgrp, re_ptrn.finditer(src_lines[src_cnt]))
        while not same_strgrp_lists(adj_matches, src_matches):
            if offset_pos == offset_max:
                if matches_differ_cnt < VERBOSITY_MATCHES_DIFFER_MAX:
                    print("warning: %s: matches (number/type) differ between"
                          " files (lines %d/%d..%d)"
                          % (base, adj_cnt, src_cnt - offset_pos, src_cnt),
                          file=stderr)
                    matches_differ_cnt+=1
                elif matches_differ_cnt == VERBOSITY_MATCHES_DIFFER_MAX:
                    print("warning: %s: too many matches differences,"
                          " giving up reporting them all" % base, file=stderr)
                    matches_differ_cnt+=1
                src_cnt -= offset_pos  # restore `src_text' position (line)
                break
            elif VERBOSITY_NOTES:
                print("note: %s: lines do not correspond with each other,"
                      " trying lines around (lines %d/%d)"
                      % (base, adj_cnt, src_cnt), file=stderr)

            while not same_strgrp_lists(adj_matches, src_matches) \
                  and offset_pos < offset_max:
                src_cnt += 1
                if src_cnt >= src_lnum: offset_pos = offset_max; break  # EOF
                offset_pos += 1
                src_matches = map(mobj_to_strgrp,
                                  re_ptrn.finditer(src_lines[src_cnt]))

        if offset_pos < offset_max:
            batch_substitution_add(matches_dict, adj_matches, src_matches)
            src_cnt += 1
            offset_max = OFFSET_LIMIT/2
            #if offset_max > 1:
            #    offset_max -= 1
        else:
            if src_cnt > 0:   # `adj_text' position can be ahead `src_text'
                src_cnt -= 1  # (or do not change at all?)
            if offset_max < OFFSET_LIMIT:
                offset_max += 1
        adj_cnt += 1

    fdst.write(subst_apply_f(matches_dict, adj_text))
    if (dest_file != "-"):
        fdst.close()
    return 0

if __name__ == "__main__":
    if len(argv) >= 3:
        pattern = RE_ADDR_STR
        subst_apply_f = batch_substitution_apply_better
        if len(argv) >= 4 and argv[1] == "-f":
            subst_apply_f = batch_substitution_apply_faster
            argv = argv[1:]
        if len(argv) >= 4 and argv[1] == "-r":
            pattern += "|"+RE_REGNUM_STR
            argv = argv[1:]
        if exists(argv[1]) and exists(argv[2]):
            dest_file = "-"
            f = open(argv[1], "r"); adj_text = f.read(); f.close()
            f = open(argv[2], "r"); src_text = f.read(); f.close()
            if len(argv) >= 4:
                dest_file = argv[3]
            sysexit(addr_reg_adj(adj_text, src_text, pattern, subst_apply_f,
                              dest_file))
        else:
            print("error: cannot read input file(s)", file=stderr); sysexit(1)
    else:
        # "f" for be faster/less accurate proceeding
        # "r" for involve register numbers
        print("Usage: %s [-f] [-r] adj_file src_file [dest_file]"%argv[0])
        sysexit(2)
